# ML1010 - Project - Phishing Website Detector

Project for the ML1010 course implements a phishing detection model for websites.

## Installation

To install the _Python_ program locally, first create a virtual environment:

```sh
$ python3 -m venv venv
$ source ./bin/venv/activate
$ (venv)
```

Next, install the required modules:

```sh
$ (venv) pip install -r requirements.txt
```

## Usage

The training process requires three (3) phases:

1. The dataset must be generated by extracting the features via parsing raw webpages;
1. The model can then be generated using the extracted data; and
1. The app can be loaded locally to assess new URLs.

All these steps can be performed using the `app.py`, which usage is as follow:

```sh
usage: app.py [-h] [-t] [--parse DATA_DIR] [--class DATA_CLASS] [-p PORT] [-m MODEL] [-v]

optional arguments:
  -h, --help            show this help message and exit
  -t, --train           Train a new model without starting the web server.
  --parse DATA_DIR      Parses HTML webpages in the given directory.
  --class DATA_CLASS    Classification of the data contained in the the directory specified in the `--parse` option.
  -p PORT, --port PORT  Port to listen on for HTTP requests.
  -m MODEL, --model MODEL
                        Model file to use.
  -v, --verbose         Display additional information about execution.
```

### Parse Webpages

To parse the webpages, use the `--parse` and `--class` options and specify the directory containing the files to parse. This should be done twice: once for the benign webpage and a second time for the malicious webpages. This will generate a `data-benign.csv` file in the `./data` directory.

```sh
$ python3 app.py --parse ./data/sample/benign/ --class benign
INFO:__main__:Parsing webpages in './data/sample/benign/'.
[nltk_data] Downloading package punkt to /home/vboxuser/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/vboxuser/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
DEBUG:webparse: Processing '0a610dcd1aae111b0597d18d4e8760e0d7e99397fbdf5cfeab1e5bdc7d73e36d.htm'.
DEBUG:webparse: Processing '0a37e43f1f8b5a93726f0e63c04ac5e20d8932d18f1acbaf30920bf6e714658b.htm'.
[...]
```

Perform the same for malicious webpages to generate the `data-malicious.csv` dataset:

```sh
$ python3 app.py --parse ./data/sample/malicious/ --class malicious
```

You can them merge both files into a single `data.csv` file:

```sh
$ cp ./data/data-benign.csv ./data/data.csv
$	tail -n +2 ./data/data-malicious.csv >> ./data/data.csv
$	wc -l ./data/data.csv
```

All these steps can be perform automatically using the `make` command:

```sh
$ make data
```

To run the server locally, simply use the following command:

```sh
$ (venv) python3 app.py
```

## Application

* [App on Heroku](https://ml1kp3.herokuapp.com/)

## References

* [Dataset](https://www.kaggle.com/datasets/asifejazitu/phishing-dataset)